package main

import (
	"encoding/json"
	"fmt"
	"log"
	"net/http"
	"net/url"
	"regexp"
	"sort"
	"strconv"
	"strings"
	"time"
)

// handleCustomRSSFeed processes custom RSS workflow configurations and generates RSS feeds
func (app *App) handleCustomRSSFeed(w http.ResponseWriter, r *http.Request) {
	// Get the encoded configuration
	configParam := r.URL.Query().Get("config")
	if configParam == "" {
		http.Error(w, "Configuration parameter 'config' is required", http.StatusBadRequest)
		return
	}

	// Check cache first
	cacheKey := "custom-rss:" + configParam
	app.rssMutex.RLock()
	if cached, exists := app.rssCache[cacheKey]; exists {
		// Cache for 10 minutes
		if time.Since(cached.timestamp) < 10*time.Minute {
			app.rssMutex.RUnlock()
			w.Header().Set("Content-Type", "application/rss+xml; charset=utf-8")
			w.Write([]byte(cached.content))
			return
		}
	}
	app.rssMutex.RUnlock()

	// Decode the configuration (URL-encoded instead of base64)
	configJSON, err := url.QueryUnescape(configParam)
	if err != nil {
		log.Printf("Error decoding URL config: %v, input: %s", err, configParam[:min(100, len(configParam))])
		http.Error(w, "Invalid configuration encoding", http.StatusBadRequest)
		return
	}

	var config CustomRSSConfig
	if err := json.Unmarshal([]byte(configJSON), &config); err != nil {
		http.Error(w, "Invalid configuration format", http.StatusBadRequest)
		return
	}

	// Process the workflow
	results, err := app.processCustomRSSWorkflow(&config)
	if err != nil {
		http.Error(w, fmt.Sprintf("Error processing workflow: %v", err), http.StatusInternalServerError)
		return
	}

	// Find output node for RSS metadata
	var outputNode *CustomRSSNode
	for _, node := range config.Nodes {
		if node.Type == "output" {
			outputNode = &node
			break
		}
	}

	// Generate RSS feed
	title := "Custom RSS Feed"
	description := "A custom RSS feed generated by BlogNerd"
	
	if outputNode != nil {
		if titleStr, ok := outputNode.Inputs["title"].(string); ok && titleStr != "" {
			title = titleStr
		}
		if descStr, ok := outputNode.Inputs["description"].(string); ok && descStr != "" {
			description = descStr
		}
	}

	rssContent := app.generateCustomRSSFeed(results, title, description, r)

	// Cache the result
	app.rssMutex.Lock()
	app.rssCache[cacheKey] = RSSCacheItem{
		content:   rssContent,
		timestamp: time.Now(),
	}
	app.rssMutex.Unlock()

	// Clean old cache entries occasionally
	go app.cleanRSSCache()

	w.Header().Set("Content-Type", "application/rss+xml; charset=utf-8")
	w.Write([]byte(rssContent))
}

// processCustomRSSWorkflow executes the custom RSS workflow and returns results
func (app *App) processCustomRSSWorkflow(config *CustomRSSConfig) ([]SearchResult, error) {
	var allResults []SearchResult

	// Find source nodes
	sourceNodes := make([]CustomRSSNode, 0)
	for _, node := range config.Nodes {
		if node.Type == "search-source" {
			sourceNodes = append(sourceNodes, node)
		}
	}

	if len(sourceNodes) == 0 {
		return nil, fmt.Errorf("no source nodes found in workflow")
	}

	// Find output node
	var outputNode *CustomRSSNode
	for i, node := range config.Nodes {
		if node.Type == "output" {
			outputNode = &config.Nodes[i]
			break
		}
	}

	if outputNode == nil {
		return nil, fmt.Errorf("no output node found in workflow")
	}

	// Process each source independently through its path
	for _, sourceNode := range sourceNodes {
		var sourceResults []SearchResult
		var err error

		switch sourceNode.Type {
		case "search-source":
			sourceResults, err = app.processSearchSource(&sourceNode)
		default:
			log.Printf("Unknown source node type: %s", sourceNode.Type)
			continue
		}

		if err != nil {
			log.Printf("Error processing source node %s: %v", sourceNode.ID, err)
			continue
		}

		// Process this source through its specific path
		pathResults := app.processPath(sourceNode.ID, sourceResults, outputNode.ID, config)
		allResults = append(allResults, pathResults...)
	}

	// Deduplicate by URL
	deduplicatedResults := app.deduplicateResults(allResults)

	// Sort by time descending for RSS output
	sort.Slice(deduplicatedResults, func(i, j int) bool {
		timeI := parseDate(deduplicatedResults[i].Date)
		timeJ := parseDate(deduplicatedResults[j].Date)
		return timeI.After(timeJ)
	})

	return deduplicatedResults, nil
}


// processSearchSource executes a search query
func (app *App) processSearchSource(node *CustomRSSNode) ([]SearchResult, error) {
	if node == nil {
		return nil, fmt.Errorf("node cannot be nil")
	}

	queryInterface, exists := node.Inputs["query"]
	if !exists {
		return nil, fmt.Errorf("search source missing query input")
	}

	query, ok := queryInterface.(string)
	if !ok || query == "" {
		return nil, fmt.Errorf("search source query must be a non-empty string")
	}

	// Get search type with validation
	searchType := "pages" // default
	if typeInterface, exists := node.Inputs["type"]; exists {
		if typeStr, ok := typeInterface.(string); ok && typeStr != "" {
			// Validate search type
			validTypes := map[string]bool{
				"pages": true, "feeds": true, "blogs": true, "news": true,
			}
			if validTypes[typeStr] {
				searchType = typeStr
			} else {
				log.Printf("Invalid search type '%s', using default 'pages'", typeStr)
			}
		}
	}

	// Create params for the search
	params := map[string][]string{
		"qry":  {query},
		"type": {searchType},
	}

	results, _ := app.performSearch(query, params)
	return results, nil
}

// applyCustomFilters applies keyword and regex filters to results
func (app *App) applyCustomFilters(results []SearchResult, config *CustomRSSConfig) []SearchResult {
	filteredResults := make([]SearchResult, 0, len(results))

	for _, result := range results {
		include := true

		// Apply each filter node
		for _, node := range config.Nodes {
			if node.Type == "text-filter" {
				include = app.applyContentFilter(&result, &node) && include
			}
		}

		if include {
			filteredResults = append(filteredResults, result)
		}
	}

	return filteredResults
}

// applyContentFilter applies text filtering (keyword or regex) to a result
func (app *App) applyContentFilter(result *SearchResult, node *CustomRSSNode) bool {
	// Get filter type (keyword or regex)
	filterType := "keyword" // default
	if typeInterface, exists := node.Inputs["type"]; exists {
		if typeStr, ok := typeInterface.(string); ok && typeStr != "" {
			filterType = typeStr
		}
	}

	if filterType == "regex" {
		return app.applyRegexFilter(result, node)
	} else {
		return app.applyKeywordFilter(result, node)
	}
}

// applyKeywordFilter applies keyword filtering to a result
func (app *App) applyKeywordFilter(result *SearchResult, node *CustomRSSNode) bool {
	patternInterface, exists := node.Inputs["pattern"]
	if !exists {
		return true // No pattern means pass through
	}

	pattern, ok := patternInterface.(string)
	if !ok || pattern == "" {
		return true
	}

	mode := "include" // default
	if modeInterface, exists := node.Inputs["mode"]; exists {
		if modeStr, ok := modeInterface.(string); ok {
			mode = modeStr
		}
	}

	keywordList := strings.Split(strings.ToLower(pattern), ",")
	text := strings.ToLower(result.Title + " " + result.Subtitle)

	hasMatch := false
	for _, keyword := range keywordList {
		keyword = strings.TrimSpace(keyword)
		if keyword != "" && strings.Contains(text, keyword) {
			hasMatch = true
			break
		}
	}

	if mode == "include" {
		return hasMatch
	} else { // exclude
		return !hasMatch
	}
}

// applyRegexFilter applies regex filtering to a result
func (app *App) applyRegexFilter(result *SearchResult, node *CustomRSSNode) bool {
	patternInterface, exists := node.Inputs["pattern"]
	if !exists {
		return true // No pattern means pass through
	}

	pattern, ok := patternInterface.(string)
	if !ok || pattern == "" {
		return true
	}

	mode := "include" // default
	if modeInterface, exists := node.Inputs["mode"]; exists {
		if modeStr, ok := modeInterface.(string); ok {
			mode = modeStr
		}
	}

	// Compile regex pattern
	regex, err := regexp.Compile(pattern)
	if err != nil {
		log.Printf("Invalid regex pattern: %s", pattern)
		return true // Invalid pattern, pass through
	}

	text := result.Title + " " + result.Subtitle
	hasMatch := regex.MatchString(text)

	if mode == "include" {
		return hasMatch
	} else { // exclude
		return !hasMatch
	}
}

// applyCustomProcessors applies sort, limit, and merge operations
func (app *App) applyCustomProcessors(results []SearchResult, config *CustomRSSConfig) []SearchResult {
	processedResults := results

	// Apply sort processors
	for _, node := range config.Nodes {
		if node.Type == "sort" {
			processedResults = app.applySortProcessor(processedResults, &node)
		}
	}

	// Apply limit processors
	for _, node := range config.Nodes {
		if node.Type == "limit" {
			processedResults = app.applyLimitProcessor(processedResults, &node)
		}
	}

	return processedResults
}

// applySortProcessor sorts results based on specified criteria
func (app *App) applySortProcessor(results []SearchResult, node *CustomRSSNode) []SearchResult {
	order := "desc" // default
	if orderInterface, exists := node.Inputs["order"]; exists {
		if orderStr, ok := orderInterface.(string); ok {
			order = orderStr
		}
	}

	sortedResults := make([]SearchResult, len(results))
	copy(sortedResults, results)

	sort.Slice(sortedResults, func(i, j int) bool {
		dateI := parseDate(sortedResults[i].Date)
		dateJ := parseDate(sortedResults[j].Date)
		
		if order == "desc" {
			return dateI.After(dateJ)
		} else {
			return dateI.Before(dateJ)
		}
	})

	return sortedResults
}

// applyLimitProcessor limits the number of results
func (app *App) applyLimitProcessor(results []SearchResult, node *CustomRSSNode) []SearchResult {
	countInterface, exists := node.Inputs["count"]
	if !exists {
		return results
	}

	var count int
	switch v := countInterface.(type) {
	case string:
		if parsed, err := strconv.Atoi(v); err == nil {
			count = parsed
		} else {
			return results
		}
	case float64:
		count = int(v)
	case int:
		count = v
	default:
		return results
	}

	if count <= 0 || count >= len(results) {
		return results
	}

	return results[:count]
}

// processPath processes items through a specific path from source to output
func (app *App) processPath(startNodeID string, items []SearchResult, outputNodeID string, config *CustomRSSConfig) []SearchResult {
	currentItems := items
	visited := make(map[string]bool)
	queue := []struct {
		nodeID string
		items  []SearchResult
	}{{startNodeID, currentItems}}

	for len(queue) > 0 {
		current := queue[0]
		queue = queue[1:]

		if visited[current.nodeID] {
			continue
		}
		visited[current.nodeID] = true
		currentItems = current.items

		// If we reached the output, return the items
		if current.nodeID == outputNodeID {
			return currentItems
		}

		// Find next nodes in this path
		nextConnections := make([]CustomRSSConnection, 0)
		for _, conn := range config.Connections {
			if conn.From == current.nodeID {
				nextConnections = append(nextConnections, conn)
			}
		}

		for _, conn := range nextConnections {
			// Find the next node
			var nextNode *CustomRSSNode
			for i, node := range config.Nodes {
				if node.ID == conn.To {
					nextNode = &config.Nodes[i]
					break
				}
			}

			if nextNode == nil {
				continue
			}

			// Apply transformations based on next node type
			processedItems := currentItems

			switch nextNode.Type {
			case "content-filter":
				filtered := make([]SearchResult, 0)
				for _, item := range processedItems {
					if app.applyContentFilter(&item, nextNode) {
						filtered = append(filtered, item)
					}
				}
				processedItems = filtered

			case "sort":
				processedItems = app.applySortProcessor(processedItems, nextNode)

			case "limit":
				processedItems = app.applyLimitProcessor(processedItems, nextNode)
			}

			queue = append(queue, struct {
				nodeID string
				items  []SearchResult
			}{nextNode.ID, processedItems})
		}
	}

	return currentItems
}

// deduplicateResults removes duplicate items by URL
func (app *App) deduplicateResults(results []SearchResult) []SearchResult {
	seen := make(map[string]bool)
	deduplicated := make([]SearchResult, 0)

	for _, result := range results {
		if !seen[result.URL] {
			seen[result.URL] = true
			deduplicated = append(deduplicated, result)
		}
	}

	return deduplicated
}

// generateCustomRSSFeed creates an RSS feed from custom workflow results
func (app *App) generateCustomRSSFeed(results []SearchResult, title, description string, r *http.Request) string {
	// Limit results to 50 items for RSS feed
	maxItems := 50
	if len(results) > maxItems {
		results = results[:maxItems]
	}

	now := time.Now().UTC()
	pubDate := now.Format(time.RFC1123Z)

	rss := `<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
<title>` + escapeXML(title) + `</title>
<description>` + escapeXML(description) + `</description>
<link>` + fmt.Sprintf("https://%s/", r.Host) + `</link>
<lastBuildDate>` + pubDate + `</lastBuildDate>
<pubDate>` + pubDate + `</pubDate>
<generator>BlogNerd Custom RSS</generator>
`

	for _, result := range results {
		itemTitle := result.Title
		if itemTitle == "" {
			itemTitle = "Untitled"
		}

		itemDescription := result.Subtitle
		if itemDescription == "" {
			itemDescription = "No description available"
		}

		itemURL := result.URL
		if itemURL == "" {
			continue // Skip items without URLs
		}

		// Use result date or current time
		itemDate := result.Date
		if itemDate == "" {
			itemDate = now.Format("2006-01-02 15:04:05")
		}

		// Convert to RFC1123Z format for RSS
		itemPubDate := pubDate
		if parsedDate := parseDate(itemDate); !parsedDate.IsZero() {
			itemPubDate = parsedDate.Format(time.RFC1123Z)
		}

		rss += `<item>
<title>` + escapeXML(itemTitle) + `</title>
<description>` + escapeXML(itemDescription) + `</description>
<link>` + escapeXML(itemURL) + `</link>
<guid>` + escapeXML(itemURL) + `</guid>
<pubDate>` + itemPubDate + `</pubDate>
<source>` + escapeXML(result.BaseDomain) + `</source>
</item>
`
	}

	rss += `</channel>
</rss>`

	return rss
}